{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFCBbQ6WUKI5"
   },
   "source": [
    "# 加载谷歌云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yF8x9g3_Nf3k"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYkorvYdle8m"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download -d mateuszbuda/lgg-mri-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4Y4Y6kunDKp"
   },
   "outputs": [],
   "source": [
    "mkdir /home/jupyter/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiKUeNtCzaRJ"
   },
   "outputs": [],
   "source": [
    "mv ./kaggle.json /home/jupyter/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T11:39:35.193841Z",
     "iopub.status.busy": "2022-05-07T11:39:35.193509Z",
     "iopub.status.idle": "2022-05-07T11:39:35.927775Z",
     "shell.execute_reply": "2022-05-07T11:39:35.926833Z",
     "shell.execute_reply.started": "2022-05-07T11:39:35.193788Z"
    }
   },
   "outputs": [],
   "source": [
    "! rm -rf *.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJR9d7QlYkit"
   },
   "source": [
    "# 加载包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnhMsZadYkiu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as ff\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8gKi0swTDS7"
   },
   "source": [
    "# 加载Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3EBLU6DYkiu"
   },
   "source": [
    "## 生成pandas格式的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-YaYL6XxBK2",
    "outputId": "37eaf915-4bfa-4845-d5b5-e49753f73cb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据集路径\n",
    "# data_dir = \"/content/kaggle_3m\"   \n",
    "data_dir = \"./kaggle_3m\"\n",
    "\n",
    "# 生成mask和img的路径地址array\n",
    "images_dir = []\n",
    "masks_dir = []\n",
    "masks_dir = glob(data_dir + '/*/*_mask*')\n",
    "\n",
    "for i in masks_dir:\n",
    "    images_dir.append(i.replace('_mask',''))\n",
    "\n",
    "print(\"image的长度{}, image前两张{}\".format(len(images_dir), images_dir[:2]))\n",
    "print(\"mask的长度{}, mask前两张{}\".format(len(masks_dir), masks_dir[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XWZPt8z0EbJ",
    "outputId": "038a4614-b135-4224-f149-e6c085378de4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'images':images_dir,'masks':masks_dir})\n",
    "data[\"images\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goplJYDqYkiw"
   },
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vPagO_B0tJ_",
    "outputId": "efb3636f-24d1-44c2-f15a-bc25e2175952",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化第\n",
    "pic_list=[265,895,95]\n",
    "for N in pic_list:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    img = cv2.imread(data.images.iloc[N])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,3,2)\n",
    "    msk=cv2.imread(data.masks.iloc[N])\n",
    "    msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n",
    "    plt.title(\"label\")\n",
    "    plt.imshow(msk)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"mask\")\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87WEBb5nYkiw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = cv2.imread(data.masks.iloc[95])\n",
    "a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-C0sAYLYkix",
    "outputId": "e4698ffa-4111-476c-cf6e-561d16f64294",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8OxX4211YWA",
    "outputId": "c54e60cb-e0c4-4a71-9dbb-0908dcbf7962",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看值得分布\n",
    "msk=cv2.imread(data.masks.iloc[95])\n",
    "print(msk.shape)\n",
    "print(np.unique(msk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfDKAKQFYkix"
   },
   "source": [
    "## 对label编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rei3FFd59yK5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelProcessor:\n",
    "    \"\"\"对标签图像的编码, 生成1通道的每个像素是类别的array\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colormap = self.read_color_map()\n",
    "        self.cm2lbl = self.encode_label_pix(self.colormap)\n",
    "    \n",
    "    # 标签编码，返回 1通道 的 已编码的标签 eg: [0000000][0011000][0000000]\n",
    "    def encode_label_img(self, img):\n",
    "        data = np.array(img, dtype='int32')\n",
    "        idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "        return np.array(self.cm2lbl[idx], dtype='int64')\n",
    "    \n",
    "    # 加载color map, eg: 第0个->黑色, 第1个->白色\n",
    "    @staticmethod\n",
    "    def read_color_map():  \n",
    "        colormap = []\n",
    "        colormap.append([0,0,0])\n",
    "        colormap.append([255,255,255])\n",
    "        return colormap\n",
    "    \n",
    "    # 标签编码，返回哈希表 eg: cm2lbl[0] = 0, cm2lbl[(255*256+255)*256+256] = 1\n",
    "    @staticmethod\n",
    "    def encode_label_pix(colormap):     \n",
    "        cm2lbl = np.zeros(256 ** 3)\n",
    "        for i, cm in enumerate(colormap):\n",
    "            cm2lbl[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i\n",
    "        return cm2lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9coh09UYkiy"
   },
   "source": [
    "## 构建pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOUhRHHc9zBu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    \"\"\"传入pandas格式 eg: img_path = pandas[\"image\"]\"\"\"\n",
    "    \n",
    "    def __init__(self, img_path, label_path):\n",
    "        # 读入图片和标签路径, 传入pandas格式 eg: img_path = pandas[\"image\"]\n",
    "        if not isinstance(img_path, np.ndarray):\n",
    "            self.img_path = img_path.to_numpy()\n",
    "            self.label_path = label_path.to_numpy()\n",
    "        self.labelProcessor = LabelProcessor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img_path[index]\n",
    "        label = self.label_path[index]\n",
    "        # 从文件名中读取数据（图片和标签都是png格式的图像数据）\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.imread(label)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "        # transform\n",
    "        img, label = self.img_transform(img, label)\n",
    "\n",
    "        return {'img': img, 'label': label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def img_transform(self, img, label):\n",
    "        # 对图片和标签做一些数值处理\n",
    "        transform_img = transforms.Compose([transforms.ToTensor(),  # 转tensor\n",
    "                                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "        \n",
    "        img = transform_img(img)\n",
    "        label = self.labelProcessor.encode_label_img(label)\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqXHMk1GUCh4",
    "outputId": "4ddbfa80-6bcf-413f-a82a-7b0dfe8d49b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = MRIDataset(data[\"images\"], data[\"masks\"])\n",
    "a[0][\"img\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcr7A0hDab4b"
   },
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwGsRM9XBaca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSljndIGahFr",
    "outputId": "24e3c9ed-8488-47dd-be67-af5952f28a35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "    nn.ReLU(inplace=True),\n",
    "  )\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "  def __init__(self, n_class):\n",
    "    super().__init__()\n",
    "\n",
    "    self.base_model = torchvision.models.resnet18(pretrained=False)\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "\n",
    "    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "    self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "    self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "    self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "    self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "    self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "    self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "    self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "    self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "  def forward(self, input):\n",
    "    x_original = self.conv_original_size0(input)\n",
    "    x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "    layer0 = self.layer0(input)\n",
    "    layer1 = self.layer1(layer0)\n",
    "    layer2 = self.layer2(layer1)\n",
    "    layer3 = self.layer3(layer2)\n",
    "    layer4 = self.layer4(layer3)\n",
    "\n",
    "    layer4 = self.layer4_1x1(layer4)\n",
    "    x = self.upsample(layer4)\n",
    "    layer3 = self.layer3_1x1(layer3)\n",
    "    x = torch.cat([x, layer3], dim=1)\n",
    "    x = self.conv_up3(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer2 = self.layer2_1x1(layer2)\n",
    "    x = torch.cat([x, layer2], dim=1)\n",
    "    x = self.conv_up2(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer1 = self.layer1_1x1(layer1)\n",
    "    x = torch.cat([x, layer1], dim=1)\n",
    "    x = self.conv_up1(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer0 = self.layer0_1x1(layer0)\n",
    "    x = torch.cat([x, layer0], dim=1)\n",
    "    x = self.conv_up0(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    x = torch.cat([x, x_original], dim=1)\n",
    "    x = self.conv_original_size2(x)\n",
    "\n",
    "    out = self.conv_last(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torch as t\n",
    "    device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "    rgb = t.randn(1, 3, 256, 256).to(device)\n",
    "\n",
    "    net = ResNetUNet(2).to(device)\n",
    "\n",
    "    out = net(rgb)\n",
    "\n",
    "    summary(net,(3,256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRgro6DBbyNQ"
   },
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a,b= np.array([1,2,3,4]).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y,u = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDbDd0CgcWRn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import six\n",
    "\n",
    "\n",
    "def calc_semantic_segmentation_confusion(pred_labels, gt_labels):\n",
    "    pred_labels = pred_labels.flatten()\n",
    "    gt_labels = gt_labels.flatten()\n",
    "    confusion = confusion_matrix(gt_labels, pred_labels)\n",
    "    if len(confusion)!= 2:\n",
    "        confusion =  np.array([confusion[0][0],0,0,0]).reshape(2,2)\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def calc_semantic_segmentation_iou(confusion):\n",
    "    intersection = np.diag(confusion)\n",
    "    union = np.sum(confusion, axis=1) + np.sum(confusion, axis=0) - np.diag(confusion)\n",
    "    Ciou = (intersection / (np.maximum(1.0, union)+  1e-10) )\n",
    "    mIoU = np.nanmean(Ciou)\n",
    "    return mIoU\n",
    "\n",
    "def calc_semantic_segmentation_dice(confusion):\n",
    "    a, b = confusion\n",
    "    tn, fp = a\n",
    "    fn, tp = b\n",
    "    return np.nanmean(2*tp/(2*tp + fn + fp+  1e-10))\n",
    "\n",
    "def eval_semantic_segmentation(pred_labels, gt_labels):\n",
    "    confusion = calc_semantic_segmentation_confusion(pred_labels, gt_labels)\n",
    "    mIoU = calc_semantic_segmentation_iou(confusion) \n",
    "    pixel_accuracy = np.nanmean(np.diag(confusion) / (confusion.sum(axis=1)+1e-10))\n",
    "    class_accuracy = np.diag(confusion) / ( confusion.sum(axis=1) +  1e-10 )\n",
    "    dice = calc_semantic_segmentation_dice(confusion)\n",
    "\n",
    "    return {'miou': mIoU,\n",
    "            'pixel_accuracy': pixel_accuracy,\n",
    "            'class_accuracy': class_accuracy,\n",
    "            'dice': dice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QXNuOa9oHRX",
    "outputId": "17e589c4-914d-4f5c-f8f9-30807abb4ea5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb = t.randn(1, 3, 64, 64)\n",
    "net =  ResNetUNet(2)\n",
    "out = net(rgb)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtQGW0BIoI8N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = F.log_softmax(out, dim=1)\n",
    "out = out.max(dim=1)[1].data.cpu().numpy()\n",
    "true_label = torch.randint(0,2,(1,64,64)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTc9oCQnpY7B",
    "outputId": "72677d5e-6ba0-4289-89bb-7bc3d2b2f1db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_semantic_segmentation(out,true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-AkFLuDgMA5"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxP16rSHuTHG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 测试训练分割\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data,test_size=0.2, shuffle=True, random_state=233)\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(device)\n",
    "num_class = 2\n",
    "\n",
    "Load_train = MRIDataset(train[\"images\"], train[\"masks\"])\n",
    "Load_val= MRIDataset(test[\"images\"], test[\"masks\"])\n",
    "\n",
    "train_data = DataLoader(Load_train, batch_size=4, shuffle=True, num_workers=1)\n",
    "val_data = DataLoader(Load_val, batch_size=4, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9uyeEiuxJwY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_unet = ResNetUNet(2)\n",
    "res_unet = res_unet.to(device)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "optimizer = optim.Adam(res_unet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model = model.eval()\n",
    "    num_class = 2\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    eval_miou = 0\n",
    "    eval_class_acc = 0\n",
    "    eval_dice = 0\n",
    "    error = 0\n",
    "\n",
    "    for j, sample in enumerate(val_data):\n",
    "        valImg = sample['img'].to(device)\n",
    "        valLabel = sample['label'].long().to(device)\n",
    "        \n",
    "        out = model(valImg)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        loss = criterion(out, valLabel)\n",
    "        eval_loss = loss.item() + eval_loss\n",
    "        \n",
    "        # 评估\n",
    "        pre_label = out.max(dim=1)[1].data.cpu().numpy()\n",
    "        true_label = valLabel.data.cpu().numpy()\n",
    "        eval_metrics = eval_semantic_segmentation(pre_label, true_label)\n",
    "        eval_acc = eval_metrics['pixel_accuracy'] + eval_acc\n",
    "        eval_miou = eval_metrics['miou'] + eval_miou\n",
    "\n",
    "        eval_class_acc =  eval_metrics['class_accuracy'] + eval_class_acc\n",
    "        eval_dice = eval_metrics['dice'] + eval_dice\n",
    "\n",
    "    val_str = '|val Acc|: {:.5f}\\n|val dice|: {:.5f}\\n|val Mean IoU|: {:.5f}\\n|val_class_acc|: {:}'.format(\n",
    "        eval_acc / len(val_data),\n",
    "        eval_dice / len(val_data),\n",
    "        eval_miou / len(val_data),\n",
    "        eval_class_acc / (len(val_data)-error))\n",
    "    print(val_str)\n",
    "    \n",
    "    return eval_acc / len(val_data), eval_dice / len(val_data), eval_miou / len(val_data), eval_class_acc / (len(val_data)-error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V0yh0lUxcAS",
    "outputId": "5c87aeec-6068-4849-f552-94106169234c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = res_unet.train()\n",
    "\n",
    "best = [0]\n",
    "Epoch = 30\n",
    "train_acc_epoch = []\n",
    "train_miou_epoch = []\n",
    "train_dice_epoch = []\n",
    "train_class_acc_epoch = []\n",
    "\n",
    "test_acc_epoch = []\n",
    "test_miou_epoch = []\n",
    "test_dice_epoch = []\n",
    "test_class_acc_epoch = []\n",
    "\n",
    "# 训练轮次\n",
    "for epoch in range(Epoch):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_miou = 0\n",
    "    train_dice = 0\n",
    "    train_class_acc = 0\n",
    "    error = 0\n",
    "    print('Epoch is [{}/{}]'.format(epoch + 1, Epoch))\n",
    "\n",
    "    # 训练批次\n",
    "    for i, sample in enumerate(train_data):\n",
    "        # 载入数据\n",
    "        img_data = sample['img'].to(device)\n",
    "        img_label = sample['label'].to(device)\n",
    "        # 训练\n",
    "        out = net(img_data)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        loss = criterion(out, img_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # 评估\n",
    "        pre_label = out.max(dim=1)[1].data.cpu().numpy()\n",
    "        true_label = img_label.data.cpu().numpy()\n",
    "        eval_metrix = eval_semantic_segmentation(pre_label, true_label)\n",
    "        train_acc += eval_metrix['pixel_accuracy']\n",
    "        train_miou += eval_metrix['miou']\n",
    "        if len(eval_metrix['class_accuracy']) < num_class:\n",
    "            eval_metrix['class_accuracy'] = 0\n",
    "            train_class_acc = train_class_acc + eval_metrix['class_accuracy']\n",
    "            error += 1\n",
    "        else:\n",
    "            train_class_acc = train_class_acc + eval_metrix['class_accuracy']\n",
    "        train_dice += eval_metrix['dice']\n",
    "        # 打印每50次\n",
    "        if i%500 ==0:\n",
    "            print('|batch[{}/{}]|batch_loss:{:.9f}|'.format(i + 1, len(train_data), loss.item()))\n",
    "\n",
    "    metric_description = '|Train Acc|: {:.5f}\\n|Train dice|: {:.5f}\\n|Train Mean IoU|: {:.5f}\\n|Train_class_acc|: {:}'.format(\n",
    "        train_acc / len(train_data),\n",
    "        train_dice / len(train_data),\n",
    "        train_miou / len(train_data),\n",
    "        train_class_acc / (len(train_data)-error))\n",
    "\n",
    "\n",
    "    print(metric_description)\n",
    "    print(\"-----------------\")\n",
    "    test_acc, test_dice, test_miou, test_class_acc = evaluate(net)\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    test_acc_epoch.append(test_acc)\n",
    "    test_miou_epoch.append(test_miou)\n",
    "    test_dice_epoch.append(test_dice)\n",
    "    test_class_acc_epoch.append(test_class_acc)\n",
    "\n",
    "    train_acc_epoch.append(train_acc / len(train_data))\n",
    "    train_miou_epoch.append(train_miou / len(train_data))\n",
    "    train_dice_epoch.append(train_dice / len(train_data))\n",
    "    train_class_acc_epoch.append(list(train_class_acc / (len(train_data)-error)))\n",
    "\n",
    "    # 储存模型\n",
    "    if max(best) <= test_dice:\n",
    "        best.append(test_dice)\n",
    "        t.save(net.state_dict(), './{}.pth'.format(epoch))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvPBJ-QUYki3",
    "outputId": "ebb9a1c5-ec5e-47e8-d84a-af2d2a1b7c72",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_class_acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dice_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EjMTNYGHozY"
   },
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT-bXv-RM2xE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8Z-Xv22FWcO",
    "outputId": "16f9518e-9ef3-4a20-954a-79243fce3b74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB9Ct3NK28Zw",
    "outputId": "efb410eb-f921-4f90-efa7-375c1ae2f6dd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = ResNetUNet(2)\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load('28.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3dz79G1DP5R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_acc = 0\n",
    "train_miou = 0\n",
    "train_class_acc = 0\n",
    "train_mpa = 0\n",
    "error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN-VQgNZN1EO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    net = model.eval()\n",
    "    num_class = 2\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    eval_miou = 0\n",
    "    eval_class_acc = 0\n",
    "    eval_dice = 0\n",
    "    error = 0\n",
    "\n",
    "    for j, sample in enumerate(val_data):\n",
    "        valImg = sample['img'].to(device)\n",
    "        valLabel = sample['label'].long().to(device)\n",
    "        \n",
    "        out = net(valImg)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        loss = criterion(out, valLabel)\n",
    "        eval_loss = loss.item() + eval_loss\n",
    "        \n",
    "        # 评估\n",
    "        pre_label = out.max(dim=1)[1].data.cpu().numpy()\n",
    "        true_label = valLabel.data.cpu().numpy()\n",
    "        eval_metrics = eval_semantic_segmentation(pre_label, true_label)\n",
    "        eval_acc = eval_metrics['pixel_accuracy'] + eval_acc\n",
    "        eval_miou = eval_metrics['miou'] + eval_miou\n",
    "\n",
    "        eval_class_acc =  eval_metrics['class_accuracy'] + eval_class_acc\n",
    "        eval_dice = eval_metrics['dice'] + eval_dice\n",
    "\n",
    "    val_str = '|val Acc|: {:.5f}\\n|val dice|: {:.5f}\\n|val Mean IoU|: {:.5f}\\n|val_class_acc|: {:}'.format(\n",
    "        eval_acc / len(val_data),\n",
    "        eval_dice / len(val_data),\n",
    "        eval_miou / len(val_data),\n",
    "        eval_class_acc / (len(val_data)-error))\n",
    "    print(val_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NYNfh6UUAud"
   },
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMyZgjJkU4iU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "colormap = []\n",
    "colormap.append([0,0,0])\n",
    "colormap.append([255,255,255])\n",
    "cm = np.array(colormap).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLBdljGUfflG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_img = test[\"images\"].to_numpy()[22:32]\n",
    "test_label = test[\"masks\"].to_numpy()[22:32]\n",
    "pd_aa = pd.DataFrame({'images':test_img,'masks':test_label})\n",
    "Load_val= MRIDataset(pd_aa['images'], pd_aa['masks'])\n",
    "val_data = DataLoader(Load_val, batch_size=10, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mec9neBVV7rL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smaples = iter(val_data)\n",
    "sample = smaples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lnz_pbrUWe8m",
    "outputId": "a98b7d1c-5c02-4512-8422-c68110ad9cdb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(sample[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpCl9AvsWEPQ",
    "outputId": "7725e9f5-6944-4bf3-bc46-36961e935877",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ulIlLBYVzkq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "valImg = sample['img'].to(device)\n",
    "valLabel = sample['label'].long().to(device)\n",
    "out = net(valImg)\n",
    "out = F.log_softmax(out, dim=1)\n",
    "pre_label = out.max(1)[1].squeeze().cpu().data.numpy()\n",
    "pre = cm[pre_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6n4j8tXjot9",
    "outputId": "03c5de57-b85f-4f82-cfb5-c9e24db7cc48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_pic = cm[sample[\"label\"]]\n",
    "true_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HBIMZ-SaaoO",
    "outputId": "c73182f1-1f8b-4260-ab50-b3c828f04edc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for N in range(10):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(1,4,1)\n",
    "    img=cv2.imread(test_img[N])\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.title(\"true\")\n",
    "    plt.imshow(true_pic[N])\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.title(\"predict\")\n",
    "    plt.imshow(pre[N])\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.title(\"ture&predict\")\n",
    "    plt.imshow(true_pic[N])\n",
    "    plt.imshow(pre[N],alpha=0.4,cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
